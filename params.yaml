logistic_regression:
  C: [0.01, 0.1, 1, 10]
  penalty: ['l1', 'l2']

decision_tree:
  max_depth: [3, 5, 10, null]
  min_samples_split: [2, 5, 10]
  min_samples_leaf: [1, 2, 4]
  criterion: ['gini', 'entropy']
  max_features: [null, 'sqrt', 'log2']

xgboost:
  n_estimators: [100, 200]
  max_depth: [3, 5, 10]
  learning_rate: [0.01, 0.1]

random_forest:
  n_estimators: [100, 200, 300]
  max_depth: [5, 10, 20, None]
  min_samples_split: [2, 5]
  min_samples_leaf: [1, 2]
  max_features: ['sqrt', 'log2', null]

lightgbm:
  num_leaves: [31, 50, 100]
  n_estimators: [100, 200, 500]
  max_depth: [-1, 5, 10, 20]
  learning_rate: [0.01, 0.05, 0.1]
